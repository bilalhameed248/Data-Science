{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4e6d352",
   "metadata": {},
   "source": [
    "## Installing Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "923b4d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab512f48",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Importing Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4016fed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import BertForQuestionAnswering\n",
    "from transformers import BertTokenizer\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe8f3e9",
   "metadata": {},
   "source": [
    "## Get Current Working Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed507328",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dir = os.getcwd() + '/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22761cfb",
   "metadata": {},
   "source": [
    "For question answering tasks, we can even use the already trained model and get decent results even when our text is from a completely different domain. To get decent results, we are using a BERT model which is fine-tuned on the SQuAD benchmark."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a09ab02",
   "metadata": {},
   "source": [
    "For our task, we will use the BertForQuestionAnswering class from the transformers library."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be466347",
   "metadata": {},
   "source": [
    "Expect the downloading to take a couple of minutes as BERT-large is a really big model with 24 layers and 340M parameters, making it a 1.34GB model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87fd0d06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a6c838eac5342079704331e567777a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/443 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f766b2458c544db39853b73153d63566",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/1.25G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f012d68701e4117b783203f922f741e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading vocab.txt:   0%|          | 0.00/226k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdd35d1f06b04cdbab5040956d683ce3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = BertForQuestionAnswering.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa7accf",
   "metadata": {},
   "source": [
    "## Saving Tokenizer and Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d3e8b50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.save_pretrained(amy_dir+\"save_tokenizer\")\n",
    "model.save_pretrained(my_dir+\"save_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e4ac0a",
   "metadata": {},
   "source": [
    "Loding Tokenizer From Save Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aab4494c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('./save_tokenizer/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1fb9d70",
   "metadata": {},
   "source": [
    "Loding Model From Save Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "58a57511",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertForQuestionAnswering.from_pretrained(\"./save_model/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78fda55a",
   "metadata": {},
   "source": [
    "## Asking a Question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1d0560cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "Stocks give you partial ownership in a corporation, while bonds are a loan from you \n",
    "to a company or government. The biggest difference between them is how they generate profit: \n",
    "stocks must appreciate in value and be sold later on the stock market, while most bonds pay\n",
    "fixed interest over time.\"\"\"\n",
    "\n",
    "question = \"what is Bond?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc8d8b7b",
   "metadata": {},
   "source": [
    "Let’s tokenize the question and text as a pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "49b0ff84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The input has a total of 63 tokens.\n"
     ]
    }
   ],
   "source": [
    "input_ids = tokenizer.encode(question, text)\n",
    "# Let’s see how many tokens this question and text pair have.\n",
    "print(\"The input has a total of {} tokens.\".format(len(input_ids)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb2d693",
   "metadata": {},
   "source": [
    "To look at what our tokenizer is doing, let’s just print out the tokens and their IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "21569071",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS]        101\n",
      "what       2,054\n",
      "is         2,003\n",
      "bond       5,416\n",
      "?          1,029\n",
      "[SEP]        102\n",
      "stocks    15,768\n",
      "give       2,507\n",
      "you        2,017\n",
      "partial    7,704\n",
      "ownership   6,095\n",
      "in         1,999\n",
      "a          1,037\n",
      "corporation   3,840\n",
      ",          1,010\n",
      "while      2,096\n",
      "bonds      9,547\n",
      "are        2,024\n",
      "a          1,037\n",
      "loan       5,414\n",
      "from       2,013\n",
      "you        2,017\n",
      "to         2,000\n",
      "a          1,037\n",
      "company    2,194\n",
      "or         2,030\n",
      "government   2,231\n",
      ".          1,012\n",
      "the        1,996\n",
      "biggest    5,221\n",
      "difference   4,489\n",
      "between    2,090\n",
      "them       2,068\n",
      "is         2,003\n",
      "how        2,129\n",
      "they       2,027\n",
      "generate   9,699\n",
      "profit     5,618\n",
      ":          1,024\n",
      "stocks    15,768\n",
      "must       2,442\n",
      "appreciate   9,120\n",
      "in         1,999\n",
      "value      3,643\n",
      "and        1,998\n",
      "be         2,022\n",
      "sold       2,853\n",
      "later      2,101\n",
      "on         2,006\n",
      "the        1,996\n",
      "stock      4,518\n",
      "market     3,006\n",
      ",          1,010\n",
      "while      2,096\n",
      "most       2,087\n",
      "bonds      9,547\n",
      "pay        3,477\n",
      "fixed      4,964\n",
      "interest   3,037\n",
      "over       2,058\n",
      "time       2,051\n",
      ".          1,012\n",
      "[SEP]        102\n"
     ]
    }
   ],
   "source": [
    "tokens = tokenizer.convert_ids_to_tokens(input_ids)\n",
    "for token, id in zip(tokens, input_ids):\n",
    "    print('{:8}{:8,}'.format(token,id))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc91cbc",
   "metadata": {},
   "source": [
    "BERT has a unique way of processing the tokenized inputs. From the above output, we can see two special tokens [CLS] and [SEP]. [CLS] token stands for classification and is there to represent sentence-level classification and is used when we are classifying. Another token used by BERT is [SEP]. It is used to separate the two pieces of text. You can see two [SEP] tokens in the above output, one after the question and another after the text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1c1b8a",
   "metadata": {},
   "source": [
    "Apart from the “Token Embeddings”, BERT internally also uses “Segment Embeddings” and “Position Embeddings”. Segment embeddings help BERT in differentiating a question from the text. In practice, we use a vector of 0's if embeddings are from sentence 1 else a vector of 1’s if embeddings are from sentence 2. Position embeddings help in specifying the position of words in the sequence. All these embeddings are fed to the input layer.\n",
    "\n",
    "Transformers library can create segment embeddings on its own using PretrainedTokenizer.encode_plus(). But, we can even create our own. For that, we just need to specify a 0 or 1 for each token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9e3d2c93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEP token index:  5\n",
      "Number of tokens in segment A:  6\n",
      "Number of tokens in segment B:  57\n"
     ]
    }
   ],
   "source": [
    "#first occurence of [SEP] token\n",
    "sep_idx = input_ids.index(tokenizer.sep_token_id)\n",
    "print(\"SEP token index: \", sep_idx)\n",
    "\n",
    "#number of tokens in segment A (question) - this will be one more than the sep_idx as the index in Python starts from 0\n",
    "num_seg_a = sep_idx+1\n",
    "print(\"Number of tokens in segment A: \", num_seg_a)\n",
    "\n",
    "#number of tokens in segment B (text)\n",
    "num_seg_b = len(input_ids) - num_seg_a\n",
    "print(\"Number of tokens in segment B: \", num_seg_b)\n",
    "\n",
    "#creating the segment ids\n",
    "segment_ids = [0]*num_seg_a + [1]*num_seg_b\n",
    "\n",
    "#making sure that every input token has a segment id\n",
    "assert len(segment_ids) == len(input_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a35bca7",
   "metadata": {},
   "source": [
    "## Let’s now feed this to our model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c05ce3",
   "metadata": {},
   "source": [
    "#token input_ids to represent the input and token segment_ids to differentiate our segments - question and text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6ab084db",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(torch.tensor([input_ids]),  token_type_ids=torch.tensor([segment_ids]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58cadd0d",
   "metadata": {},
   "source": [
    "Looking at the most probable start and end words and providing answers only if the end token is after the start token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0adc28c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Question:\n",
      "What is bond?\n",
      "\n",
      "Answer:\n",
      "A loan from you to a company or government.\n"
     ]
    }
   ],
   "source": [
    "#tokens with highest start and end scores\n",
    "answer_start = torch.argmax(output.start_logits)\n",
    "\n",
    "answer_end = torch.argmax(output.end_logits)\n",
    "\n",
    "if answer_end >= answer_start:\n",
    "    \n",
    "    answer = \" \".join(tokens[answer_start:answer_end+1])\n",
    "    \n",
    "else:\n",
    "    print(\"I am unable to find the answer to this question. Can you please ask another question?\")\n",
    "    \n",
    "print(\"\\nQuestion:\\n{}\".format(question.capitalize()))\n",
    "print(\"\\nAnswer:\\n{}.\".format(answer.capitalize()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db1f6568",
   "metadata": {},
   "source": [
    "Let us now turn this question-answering process into a function for ease."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "19d35cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def question_answer(question, text):\n",
    "    \n",
    "    #tokenize question and text as a pair\n",
    "    input_ids = tokenizer.encode(question, text)\n",
    "    \n",
    "    #string version of tokenized ids\n",
    "    tokens = tokenizer.convert_ids_to_tokens(input_ids)\n",
    "    \n",
    "    #segment IDs\n",
    "    #first occurence of [SEP] token\n",
    "    sep_idx = input_ids.index(tokenizer.sep_token_id)\n",
    "    #number of tokens in segment A (question)\n",
    "    num_seg_a = sep_idx+1\n",
    "    #number of tokens in segment B (text)\n",
    "    num_seg_b = len(input_ids) - num_seg_a\n",
    "    \n",
    "    #list of 0s and 1s for segment embeddings\n",
    "    segment_ids = [0]*num_seg_a + [1]*num_seg_b\n",
    "    assert len(segment_ids) == len(input_ids)\n",
    "    \n",
    "    #model output using input_ids and segment_ids\n",
    "    output = model(torch.tensor([input_ids]), token_type_ids=torch.tensor([segment_ids]))\n",
    "    \n",
    "    #reconstructing the answer\n",
    "    answer_start = torch.argmax(output.start_logits)\n",
    "    answer_end = torch.argmax(output.end_logits)\n",
    "    if answer_end >= answer_start:\n",
    "        answer = tokens[answer_start]\n",
    "        for i in range(answer_start+1, answer_end+1):\n",
    "            if tokens[i][0:2] == \"##\":\n",
    "                answer += tokens[i][2:]\n",
    "            else:\n",
    "                answer += \" \" + tokens[i]\n",
    "                \n",
    "    if answer.startswith(\"[CLS]\"):\n",
    "        answer = \"Unable to find the answer to your question.\"\n",
    "    \n",
    "    print(\"\\nPredicted answer:\\n{}\".format(answer.capitalize()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0fed5a77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicted answer:\n",
      "Partial ownership in a corporation\n"
     ]
    }
   ],
   "source": [
    "question = \"Where is stock?\"\n",
    "question_answer(question, text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992f6a28",
   "metadata": {},
   "source": [
    "Here, is a small function to test out how well BERT understands contexts. I just made the question answering process as a loop to play around with the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "401eeea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Please enter your question: \n",
      "What is Stock\n",
      "\n",
      "Predicted answer:\n",
      "Stocks give you partial ownership in a corporation\n",
      "\n",
      "Do you want to ask another question based on this text (Y/N)? Y\n",
      "\n",
      "Please enter your question: \n",
      "What is difference between stock and bond?\n",
      "\n",
      "Predicted answer:\n",
      "How they generate profit\n",
      "\n",
      "Do you want to ask another question based on this text (Y/N)? What is Bond\n",
      "\n",
      "Do you want to ask another question based on this text (Y/N)? Y\n",
      "\n",
      "Please enter your question: \n",
      " What is Bond?\n",
      "\n",
      "Predicted answer:\n",
      "A loan from you to a company or government\n",
      "\n",
      "Do you want to ask another question based on this text (Y/N)? N\n",
      "\n",
      "Bye!\n"
     ]
    }
   ],
   "source": [
    "question = input(\"\\nPlease enter your question: \\n\")\n",
    "while True:\n",
    "    question_answer(question, text)\n",
    "    \n",
    "    flag = True\n",
    "    flag_N = False\n",
    "    \n",
    "    while flag:\n",
    "        response = input(\"\\nDo you want to ask another question based on this text (Y/N)? \")\n",
    "        if response[0] == \"Y\":\n",
    "            question = input(\"\\nPlease enter your question: \\n\")\n",
    "            flag = False\n",
    "        elif response[0] == \"N\":\n",
    "            print(\"\\nBye!\")\n",
    "            flag = False\n",
    "            flag_N = True\n",
    "            \n",
    "    if flag_N == True:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382d8ed7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471a2583",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897146ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9bad69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef30a268",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08dc7f4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69ab331",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26461dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d46c07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea41f92b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb557c47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a68f58e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bdff357",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6ff9ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab890db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983f800d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5650fe62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1f828c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f01625",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec7da36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a22827",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8316d0cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
